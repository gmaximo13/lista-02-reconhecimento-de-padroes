# Lista 02 â€“ Reconhecimento de PadrÃµes

Este repositÃ³rio contÃ©m os cÃ³digos, grÃ¡ficos e anÃ¡lises desenvolvidas para a **Lista 02 da disciplina GAT117 - Reconhecimento de PadrÃµes** da Universidade Federal de Lavras (UFLA), ministrada em 2025.

## ğŸ‘¨â€ğŸ“ Autor
**Gustavo dos Santos Moreira MÃ¡ximo**

## ğŸ§  Objetivo

Esta atividade tem como objetivo aplicar e comparar diferentes **algoritmos de classificaÃ§Ã£o multi-classe**, estendendo os conceitos de classificadores binÃ¡rios. Os algoritmos abordados incluem:

- **Discriminante de Fisher** (abordagem One-vs-Rest)
- **Perceptron** (abordagem One-vs-Rest)

---

## âš™ï¸ ExecuÃ§Ã£o dos CÃ³digos

Para executar os cÃ³digos e reproduzir os resultados, siga os passos abaixo:

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone https://github.com/gmaximo13/lista-02-reconhecimento-de-padroes.git
    ```

2.  **Instale as dependÃªncias:**
    ```bash
    pip install numpy pandas matplotlib scikit-learn
    ```

3.  **Execute os scripts em ordem:**

    * **Primeiro, gere os dados:**
        ```bash
        python gerar_dados_lista2.py
        ```
        Este script criarÃ¡ a pasta `data_lista_2/` e salvarÃ¡ os arquivos CSV de treino e teste nela.

    * **Em seguida, projete os classificadores (QuestÃ£o 1):**
        ```bash
        python resolver_lista2_q1.py
        ```
        Este script irÃ¡ carregar os dados de treino gerados, projetar os classificadores Discriminante de Fisher e Perceptron (One-vs-Rest), e exibir os grÃ¡ficos de projeto, alÃ©m de imprimir os parÃ¢metros (pesos e limiares) obtidos.

    * **Por fim, teste e avalie os classificadores (QuestÃ£o 2):**
        ```bash
        python resolver_lista2_q2_q3.py
        ```
        Este script irÃ¡ carregar os dados de teste e utilizar os parÃ¢metros **hardcoded** dos classificadores obtidos na QuestÃ£o 1 (os que foram impressos ao final do script `resolver_lista2_q1.py`). Ele exibirÃ¡ a matriz de confusÃ£o, mÃ©tricas de desempenho e grÃ¡ficos das fronteiras sobre os dados de teste.

---

## ğŸ§ª DescriÃ§Ã£o dos Experimentos

Os experimentos da Lista 02 focam na extensÃ£o de classificadores lineares para problemas multi-classe (3 classes) utilizando a estratÃ©gia One-vs-Rest (OvR), e na avaliaÃ§Ã£o de seu desempenho em dados nÃ£o vistos.

| QuestÃ£o | Classificador / TÃ³picoÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | Dados UsadosÂ  Â  Â  Â  Â  Â | ObservaÃ§ÃµesÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â |
|--------:|------------------------------------------------|-------------------------|------------------------------------------------------------------------------|
|Â  Â  Â  Â 1 | Discriminante de Fisher (OvR) e Perceptron (OvR) | Dados de Treino (100 amostras/classe) | Projeto dos classificadores multi-classe e visualizaÃ§Ã£o das fronteiras de decisÃ£o em relaÃ§Ã£o aos dados de treino. O Perceptron utilizado Ã© baseado no "Algoritmo Perceptron" do Slide 12 da Aula 3. |
|Â  Â  Â  Â 2 | Teste dos classificadores da QuestÃ£o 1Â  Â  Â  Â  Â  Â | Dados de Teste (100 amostras/classe)Â  | AvaliaÃ§Ã£o do desempenho dos classificadores em dados nÃ£o vistos, com Matrizes de ConfusÃ£o, mÃ©tricas de acerto por classe (Recall, PrecisÃ£o) e AcurÃ¡cia Geral. Inclui grÃ¡ficos das fronteiras sobre os dados de teste.Â  Â |

---

## ğŸ“Š ComparaÃ§Ã£o dos Algoritmos

A anÃ¡lise dos resultados, tanto nos dados de treino quanto de teste, demonstrou as caracterÃ­sticas de cada classificador:

-   O **Discriminante de Fisher (OvR)** apresentou **excelente desempenho**, mantendo 100% de acerto nas classes mesmo em dados de teste. Isso Ã© esperado, pois para dados linearmente separÃ¡veis com distribuiÃ§Ãµes Gaussianas e covariÃ¢ncias semelhantes, o Fisher se aproxima da soluÃ§Ã£o Ã³tima teÃ³rica. Suas fronteiras de decisÃ£o, que consideram a dispersÃ£o e centralidade das classes, tendem a ser mais robustas.
-   O **Perceptron (OvR)** tambÃ©m alcanÃ§ou um **alto desempenho**, inclusive 100% de acurÃ¡cia geral nos dados de teste. Apesar de suas fronteiras de decisÃ£o poderem parecer "menos ideais" visualmente em comparaÃ§Ã£o com o Fisher (jÃ¡ que o Perceptron busca *qualquer* hiperplano que separe os pontos de treino, e nÃ£o a fronteira Ã³tima probabilisticamente), ele conseguiu classificar todos os pontos de teste corretamente para este conjunto de dados linearmente separÃ¡vel.

## ğŸ“Œ ConclusÃ£o

Este estudo aprofundou a aplicaÃ§Ã£o de classificadores lineares para problemas multi-classe, utilizando a estratÃ©gia One-vs-Rest (OvR). Ficou evidente que, para conjuntos de dados linearmente separÃ¡veis e bem definidos como os utilizados, tanto o Discriminante de Fisher quanto o Perceptron sÃ£o capazes de projetar fronteiras de decisÃ£o eficazes, com o Fisher oferecendo uma soluÃ§Ã£o mais robusta do ponto de vista teÃ³rico. A avaliaÃ§Ã£o em dados de teste Ã© crucial para confirmar a capacidade de generalizaÃ§Ã£o dos modelos.

---
